{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cf9927d",
   "metadata": {},
   "source": [
    "# 分岐点の半径Rのラベルを削除して実行\n",
    "分岐点の半径Rの円内にあるスペクトラルクラスタリングのラベルを削除する\n",
    "#### 入力\n",
    "- スペクトラルクラスタリングにより20分割した画像"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00e5acc",
   "metadata": {},
   "source": [
    "### ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825ecf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import datetime\n",
    "import math\n",
    "from skimage.morphology import skeletonize\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4167b988",
   "metadata": {},
   "source": [
    "### 細線化により分岐点探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a7952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def junk(img_skel,img,img_num):\n",
    "    height,width = img_skel.shape\n",
    "    temp_j = np.zeros((height,width))\n",
    "    \n",
    "    skel_b = img.copy()\n",
    "    \n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            if(img_skel[y,x]>0):\n",
    "                skel_b[y,x] = (255,255,255)\n",
    "            else:\n",
    "                skel_b[y,x] = (0,0,0)\n",
    "    \n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            if(img_skel[y,x]==255):\n",
    "                check = 0\n",
    "                cnt = 1\n",
    "                temp_l = np.zeros((3,3))\n",
    "                \n",
    "                if(img_skel[y-1,x-1]==255):\n",
    "                    cnt += 1\n",
    "                    temp_l[0,0] = 1\n",
    "                if(img_skel[y-1,x]==255):\n",
    "                    cnt += 1\n",
    "                    temp_l[0,1] = 1\n",
    "                if(img_skel[y-1,x+1]==255):\n",
    "                    cnt += 1\n",
    "                    temp_l[0,2] = 1\n",
    "                if(img_skel[y,x-1]==255):\n",
    "                    cnt += 1\n",
    "                    temp_l[1,0] = 1\n",
    "                if(img_skel[y,x+1]==255):\n",
    "                    cnt += 1\n",
    "                    temp_l[1,2] = 1\n",
    "                if(img_skel[y+1,x-1]==255):\n",
    "                    cnt += 1\n",
    "                    temp_l[2,0] = 1\n",
    "                if(img_skel[y+1,x]==255):\n",
    "                    cnt += 1\n",
    "                    temp_l[2,1] = 1\n",
    "                if(img_skel[y+1,x+1]==255):\n",
    "                    cnt += 1\n",
    "                    temp_l[2,2] = 1\n",
    "                \n",
    "                for y_l in range(3):\n",
    "                    for x_l in range(3):\n",
    "                        if(temp_l[y_l,x_l] == 1):\n",
    "                            if((y_l-1)>=0):\n",
    "                                if(temp_l[y_l-1,x_l] == 1):\n",
    "                                    check = 1\n",
    "                            if((y_l+1)<3):\n",
    "                                if(temp_l[y_l+1,x_l] == 1):\n",
    "                                    check = 1\n",
    "                            if((x_l-1)>=0):\n",
    "                                if(temp_l[y_l,x_l-1] == 1):\n",
    "                                    check = 1\n",
    "                            if((x_l+1)<3):\n",
    "                                if(temp_l[y_l,x_l+1] == 1):\n",
    "                                    check = 1\n",
    "\n",
    "                if(cnt == 2):\n",
    "                    temp_j[y,x] = 2\n",
    "                elif((cnt > 3) and (check == 0)):\n",
    "                    temp_j[y,x] = 1\n",
    "                elif(cnt>4):\n",
    "                    temp_j[y,x] = 1\n",
    "                    \n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            if(temp_j[y,x]==1):\n",
    "                cv2.rectangle(img, (x-3, y-3), (x+3, y+3), (0, 0, 255))\n",
    "                cv2.rectangle(skel_b, (x-3, y-3), (x+3, y+3), (0, 0, 255))\n",
    "                cv2.rectangle(img_skel, (x-3, y-3), (x+3, y+3), 0, thickness=-1)\n",
    "            elif(temp_j[y,x]==2):\n",
    "                cv2.rectangle(img, (x-3, y-3), (x+3, y+3), (0, 255, 0))\n",
    "                \n",
    "    #cv2.imwrite('Output/Spectral_sys/03_skel-junktion/ORA-{0:03d}_skel-junction.png'.format(img_num),skel_b)\n",
    "                    \n",
    "    return temp_j,img,img_skel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237e4831",
   "metadata": {},
   "source": [
    "### 細線化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a14d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skel(img_num):\n",
    "\n",
    "    input_img_file = '../../flower_CT_photo/ORA/[vg-data] ORA/volume_1/ORA-{0:03d}.tif'.format(img_num)\n",
    "    \n",
    "    #Original\n",
    "    img_col = cv2.imread(input_img_file)\n",
    "\n",
    "    #NLMDを用いた2値化\n",
    "    img = cv2.imread(input_img_file,0)\n",
    "    img = cv2.fastNlMeansDenoising(img,h=6)\n",
    "    th_img = np.where(img>50 ,1 ,0)\n",
    "\n",
    "    # 細線化(スケルトン化) Zha84\n",
    "    skeleton = skeletonize(th_img)\n",
    "\n",
    "    skel_b = np.zeros((img.shape[0],img.shape[1]))\n",
    "    skel_b[skeleton==True] = 255\n",
    "    #cv2.imwrite('Output/Spectral_sys/02_skeleton/ORA-{0:03d}_skeleton.png'.format(img_num),skel_b)\n",
    "\n",
    "    #細線化画像による分岐点探索\n",
    "    temp_j,img_j,img_skel = junk(skel_b,img_col,img_num)\n",
    "    \n",
    "    #cv2.imwrite('Output/Spectral_sys/04_img-junction/ORA-{0:03d}_img-junktion.png'.format(img_num),img_j)\n",
    "    \n",
    "    return temp_j,img_skel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2221c7",
   "metadata": {},
   "source": [
    "### 全体のコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd2662f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for img_num in tqdm(range(578,850)):\n",
    "#for img_num in tqdm(range(600,601)):\n",
    "    #ファイルの指定\n",
    "    input_img_file = '../../flower_CT_photo/ORA/[vg-data] ORA/volume_1/ORA-{0:03d}.tif'.format(img_num)\n",
    "    input_SpCl_file = 'Output/Spectral_sys/01_k-means/ORA-{0:03d}_k-means-200.png'.format(img_num)\n",
    "    \n",
    "    #クラスタ数\n",
    "    k_c = 200\n",
    "    \n",
    "    #分岐点除去の半径を指定\n",
    "    r = 15\n",
    "    \n",
    "    #入力画像\n",
    "    img = cv2.imread(input_img_file,0)\n",
    "    img_NLMD = cv2.fastNlMeansDenoising(img,h=6)\n",
    "    th_img = np.where(img_NLMD>50 ,255,0)\n",
    "    \n",
    "    #ノード数カウント用\n",
    "    cnt = 1\n",
    "    \n",
    "    #ノード番号を格納する配列を定義\n",
    "    temp = np.zeros((height,width),dtype = 'i4')\n",
    "\n",
    "    #閾値以上のピクセルにノード番号付与\n",
    "    for y in tqdm(range(height)):\n",
    "        for x in range(width):\n",
    "            if(th_img[y,x]==255):\n",
    "                temp[y,x] = cnt\n",
    "                cnt += 1\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    print(now)\n",
    "    print('スペクトラルクラスタリングの結果を読み込み')\n",
    "    \n",
    "    #スペクトラルクラスタリングの結果をインポート\n",
    "    img_kmeans = cv2.imread(input_SpCl_file)\n",
    "    height,width,c = img_kmeans.shape\n",
    "    \n",
    "    #クラスタ番号を格納する配列\n",
    "    cluster = np.zeros((height,width))\n",
    "    #クラスタごとの色を管理する配列\n",
    "    color_code = np.zeros((300,3))\n",
    "    \n",
    "    #クラスタ番号のカウント用\n",
    "    i = 1\n",
    "    \n",
    "    #クラスタ番号の付与\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            if((img_kmeans[y,x,0]== img_kmeans[y,x,1]) and (img_kmeans[y,x,1] == img_kmeans[y,x,2])):\n",
    "                img_kmeans[y,x] = (0,0,0)\n",
    "            else:\n",
    "                if(i==1):\n",
    "                    color_code[i] = img_kmeans[y,x]\n",
    "                    cluster[y,x] = i\n",
    "                    i+=1\n",
    "                else:\n",
    "                    flag = 0\n",
    "                    j = 1\n",
    "\n",
    "                    while(flag != 1 and j <= i):\n",
    "                        if((color_code[j]==img_kmeans[y,x]).all()):\n",
    "                            flag = 1\n",
    "                            cluster[y,x] = j\n",
    "                        else:\n",
    "                            j += 1\n",
    "\n",
    "                    if(flag == 0):\n",
    "                        color_code[i] = img_kmeans[y,x]\n",
    "                        cluster[y,x] = i\n",
    "                        i += 1\n",
    "                        \n",
    "        now = datetime.datetime.now()\n",
    "    print(now)\n",
    "    print('細線化による分岐点探索')\n",
    "    \n",
    "    j_p,img_skel= skel(img_num)\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "    print(now)\n",
    "    print('分岐点周辺の同一クラスタを削除')\n",
    "    \n",
    "    del_cluster = np.zeros((height,width))\n",
    "    img_del_r = cv2.imread(input_img_file)\n",
    "    \n",
    "    mask = cv2.imread('reference/Dark_temp.png')\n",
    "    for y in tqdm(range(height)):\n",
    "        for x in range(width):\n",
    "            if(j_p[y,x] == 1):\n",
    "                cv2.circle(mask,(x,y),r,(255, 255, 255), thickness=-1)\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            if(mask[y,x,0]==255):\n",
    "                if(cluster[y,x]!=0):\n",
    "                    p_pred = cluster[y,x]\n",
    "                    cluster[y,x] = 0\n",
    "                    del_cluster[y,x] = img_NLMD[y,x]\n",
    "                    for y_t in range(height):\n",
    "                        for x_t in range(width):\n",
    "                            if(p_pred == cluster[y_t,x_t]):\n",
    "                                cluster[y_t,x_t] = 0\n",
    "                                del_cluster[y_t,x_t] = img_NLMD[y_t,x_t]\n",
    "\n",
    "    \"\"\"\n",
    "    colors = []\n",
    "    for i in range(1, 300):\n",
    "        colors.append(np.array([random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]))\n",
    "                                \n",
    "    img_col = cv2.imread(input_img_file)\n",
    "\n",
    "    for y in range(img_col.shape[0]):\n",
    "        for x in range(img_col.shape[1]):\n",
    "            if(temp[y,x]>0):\n",
    "                if(cluster[y,x] != 0):\n",
    "                    i = temp[y,x]-1\n",
    "                    img_col[y,x] = colors[int(pred[i])]\n",
    "    \"\"\"\n",
    "\n",
    "    #cv2.imwrite('Output/Spectral_sys/05_junk-del/ORA-{0:03d}_k-means-{1:03d}_junk-del.png'.format(img_num,k_c),img_col)\n",
    "\n",
    "    #cv2.imwrite('Output/Spectral_sys/06_junk-only/ORA-{0:03d}_k-means-{1:03d}_junk-only.png'.format(img_num,k_c),del_cluster)\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    print(now)\n",
    "    print('分岐点を除去した細線化をラベリング')\n",
    "    \n",
    "    img_col_skel = cv2.imread(input_img_file)\n",
    "    skel_col = cv2.imread(input_img_file)\n",
    "\n",
    "    img_skel = img_skel.astype('u1')\n",
    "\n",
    "    nLabels, labelImages_skel, data, center = cv2.connectedComponentsWithStatsWithAlgorithm(img_skel, 8, cv2.CV_16U, cv2.CCL_DEFAULT)\n",
    "\n",
    "    colors = []\n",
    "\n",
    "    for i in range(1, 300):\n",
    "        colors.append(np.array([random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]))\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            if(labelImages_skel[y,x]>0):\n",
    "                img_col_skel[y,x]=colors[int(labelImages_skel[y,x])]\n",
    "                skel_col[y,x]=colors[int(labelImages_skel[y,x])]\n",
    "            else:\n",
    "                skel_col[y,x]=(0,0,0)\n",
    "\n",
    "    #cv2.imwrite('Output/Spectral_sys/07-1_skel-label_onIMG/ORA-{0:03d}_skel-label_onIMG.png'.format(img_num),img_col_skel)\n",
    "    #cv2.imwrite('Output/Spectral_sys/07-2_skel-label/ORA-{0:03d}_skel-label.png'.format(img_num),skel_col)\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    print(now)\n",
    "    print('分岐点周辺を削除した画像を2値化')\n",
    "    \n",
    "    th_img_clu = cv2.imread(input_img_file,0)\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            if(cluster[y,x]>0):\n",
    "                th_img_clu[y,x]=255\n",
    "            else:\n",
    "                th_img_clu[y,x]=0\n",
    "\n",
    "    #cv2.imwrite('Output/Spectral_sys/08_junk-del-th/ORA-{0:03d}_k-means-{1:03d}_junk-del-th.png'.format(img_num,k_c),th_img_clu)\n",
    "\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    print(now)\n",
    "    print('分岐点周辺を削除した画像をラベリング')\n",
    "    \n",
    "    img_col = cv2.imread(input_img_file)\n",
    "\n",
    "    # ラベリング処理\n",
    "    nLabels, labelImages, data, center = cv2.connectedComponentsWithStatsWithAlgorithm(th_img_clu, 8, cv2.CV_16U, cv2.CCL_DEFAULT)\n",
    "\n",
    "    # オブジェクト情報を項目別に抽出\n",
    "    n = nLabels - 1\n",
    "\n",
    "    label_fix = np.zeros(nLabels)\n",
    "\n",
    "    # オブジェクト情報を利用して15ピクセル以下のラベルを削除\n",
    "    for i in range(1,nLabels):\n",
    "\n",
    "        size = data[i,4]\n",
    "        if(size<15):\n",
    "            label_fix[i]=0\n",
    "        else:\n",
    "            label_fix[i]=i\n",
    "\n",
    "    #色情報の定義\n",
    "    colors = []\n",
    "    for i in range(1, nLabels+1):\n",
    "        colors.append(np.array([random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]))\n",
    "\n",
    "    #2値化用の配列\n",
    "    label_th = np.zeros((height,width))\n",
    "\n",
    "    #ラベリングの色を付与・2値化\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            if((labelImages[y,x]>0)and(label_fix[labelImages[y,x]]>0)):\n",
    "                img_col[y,x]=colors[int(label_fix[int(labelImages[y,x])])]\n",
    "                label_th[y,x]=255\n",
    "            else:\n",
    "                cluster[y,x]=0\n",
    "\n",
    "    #ラベリング結果を保存\n",
    "    #cv2.imwrite('Output/Spectral_sys/09_junk-del-label/ORA-{0:03d}_k-means-{1:03d}_junk-del-label.png'.format(img_num,k_c),img_col)\n",
    "    #ノイズ除去した画像を保存\n",
    "    #cv2.imwrite('Output/Spectral_sys/10_junk-del-label-th/ORA-{0:03d}_k-means-{1:03d}_junk-del-label-th.png'.format(img_num,k_c),label_th)\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    print(now)\n",
    "    print('ラベリングを統合（細線化を用いて）')\n",
    "    \n",
    "    #クラスタ統合用\n",
    "    c_num = np.zeros((201))\n",
    "\n",
    "    #細線上を辿り、1つの細線に属しているクラスタを1つのクラスタに統合\n",
    "    for y in tqdm(range(height)):\n",
    "        for x in range(width):\n",
    "            if((img_skel[y,x]>0)and(cluster[y,x]>0)):\n",
    "                c_num[int(cluster[y,x])] = labelImages_skel[y,x]\n",
    "\n",
    "    #統合後のクラスタを格納\n",
    "    cluster_fix = np.zeros((height,width))\n",
    "\n",
    "    for y in tqdm(range(height)):\n",
    "        for x in range(width):\n",
    "            if(cluster[y,x]>0):\n",
    "                cluster_fix[y,x]= c_num[int(cluster[y,x])]\n",
    "\n",
    "    #統合後のクラスタを保存\n",
    "    img_col = cv2.imread(input_img_file)\n",
    "\n",
    "    colors = []\n",
    "    for i in range(1, 400):\n",
    "        colors.append(np.array([random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]))\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            if(cluster_fix[y,x]>0):\n",
    "                img_col[y,x]=colors[int(cluster_fix[y,x])]\n",
    "\n",
    "    #cv2.imwrite('Output/Spectral_sys/11_junk-del-label-inte/ORA-{0:03d}_k-means-{1:03d}_junk-del-label-inte.png'.format(img_num,k_c),img_col)\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    print(now)\n",
    "    print('同一クラスタが離れている場合はクラスタを分離')\n",
    "    \n",
    "    cnt_cl = 200\n",
    "    chk_cl = np.zeros(400)\n",
    "\n",
    "    for y in tqdm(range(height)):\n",
    "        for x in range(width):\n",
    "            if((cluster_fix[y,x]>0)and(chk_cl[int(cluster_fix[y,x])]==0)):\n",
    "\n",
    "                temp_cl = np.zeros((height,width))\n",
    "\n",
    "                for y_t in range(height):\n",
    "                    for x_t in range(width):\n",
    "                        if(cluster_fix[y,x]==cluster_fix[y_t,x_t]):\n",
    "                            temp_cl[y_t,x_t] = 255\n",
    "\n",
    "                temp_cl = temp_cl.astype('u1')\n",
    "\n",
    "                nLabels_temp, labelImages_temp, data_temp, center_temp = cv2.connectedComponentsWithStatsWithAlgorithm(temp_cl, 8, cv2.CV_16U, cv2.CCL_DEFAULT)\n",
    "\n",
    "                chk_cl[int(cluster_fix[y,x])]=1\n",
    "                if(nLabels_temp>2):\n",
    "                    for y_t in range(height):\n",
    "                        for x_t in range(width):\n",
    "                            if(labelImages_temp[y_t,x_t]>0):\n",
    "                                cluster_fix[y_t,x_t] = cnt_cl+labelImages_temp[y_t,x_t]\n",
    "                    cnt_cl += nLabels_temp-1\n",
    "\n",
    "    c_num_fix = np.zeros(500)\n",
    "\n",
    "    for y in tqdm(range(height)):\n",
    "        for x in range(width):\n",
    "            if((img_skel[y,x]>0)and(cluster_fix[y,x]>0)):\n",
    "                c_num_fix[int(cluster_fix[y,x])] = labelImages_skel[y,x]\n",
    "\n",
    "    cluster_fix2 = np.zeros((height,width))\n",
    "\n",
    "    for y in tqdm(range(height)):\n",
    "        for x in range(width):\n",
    "            if(cluster[y,x]>0):\n",
    "                cluster_fix2[y,x]= c_num_fix[int(cluster_fix[y,x])]\n",
    "\n",
    "    img_col = cv2.imread(input_img_file)\n",
    "\n",
    "    colors = []\n",
    "    for i in range(1, 500):\n",
    "        colors.append(np.array([random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]))\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            if(cluster_fix2[y,x]>0):\n",
    "                img_col[y,x]=colors[int(cluster_fix2[y,x])]\n",
    "\n",
    "    cv2.imwrite('Output/Spectral_sys/12-3_junk-del-label-inte-sp_r{0:02d}/ORA-{1:03d}_k-means-{2:03d}_junk-del-label-inte_sp_r{0:02d}.png'.format(r,img_num,k_c),img_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4bed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('Output/Spectral_sys/12-2_junk-del-label-inte-sp_r{0:02d}/ORA-{1:03d}_k-means-200_junk-del-label-inte_sp_r{0:02d}.png'.format(r,img_num),img_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b4b68e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
