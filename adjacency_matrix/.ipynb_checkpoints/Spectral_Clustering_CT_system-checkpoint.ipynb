{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "137ab5ac",
   "metadata": {},
   "source": [
    "## 1枚のCT画像をスペクトラルクラスタリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86109630",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install scikit-image scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d35095e",
   "metadata": {},
   "source": [
    "### ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a96671",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "#import networkx as nx\n",
    "import sys\n",
    "from scipy.sparse import lil_matrix\n",
    "import numpy.linalg as LA\n",
    "import datetime\n",
    "from scipy.sparse import csr_matrix, csc_matrix\n",
    "from scipy.sparse.linalg import inv, eigs, eigsh\n",
    "from scipy.sparse import diags\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import math\n",
    "from skimage.draw import line\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage, cophenet,fcluster,dendrogram\n",
    "from multiprocessing import Pool\n",
    "from collections import defaultdict\n",
    "from skimage.morphology import skeletonize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3c827b",
   "metadata": {},
   "source": [
    "### ラプラシアン行列の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a668c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian_matrix( network_matrix ,cnt):\n",
    "    n_nodes = network_matrix.shape[0]\n",
    "    \n",
    "    network_matrix = network_matrix.tocsr()\n",
    "    \n",
    "    #print(network_matrix.toarray())\n",
    "    \n",
    "    #degree_matrix = diags( np.ravel(network_matrix.sum(axis=1)), format=\"csr\")\n",
    "    degree_matrix = diags( np.ravel(network_matrix.sum(axis=1)))\n",
    "    #print(type(network_matrix))\n",
    "    \n",
    "    #print(degree_matrix)\n",
    "    \n",
    "    laplacian_matrix = degree_matrix - network_matrix\n",
    "    \n",
    "    degree_matrix = degree_matrix.tolil()\n",
    "    \n",
    "    D_i = lil_matrix((degree_matrix.shape[0],degree_matrix.shape[1]),dtype='float')\n",
    "    \n",
    "    for i in tqdm(range(degree_matrix.shape[0])):\n",
    "        D_i[i,i]= 1/degree_matrix[i,i]\n",
    "        \n",
    "    D_i = D_i.tocsr()\n",
    "    D_i_s = D_i.sqrt()\n",
    "    \n",
    "    #print(type(D_i))\n",
    "    \n",
    "    #L_rw = D_i * laplacian_matrix\n",
    "    L_sym = D_i_s * laplacian_matrix * D_i_s\n",
    "    \n",
    "    #return laplacian_matrix\n",
    "    return L_sym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3052342e",
   "metadata": {},
   "source": [
    "### 固有値計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe1c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigen_2nd( network_matrix ,cnt):\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    print(now)\n",
    "    print('ラプラシアン行列作成')\n",
    "    \n",
    "    L = laplacian_matrix(network_matrix,cnt)\n",
    "    \n",
    "    print(L)\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    print(now)\n",
    "    print('固有値計算作成')\n",
    "\n",
    "    values, vectors = eigs(L,200,which='SR')\n",
    "    \n",
    "    print(values)\n",
    "    print(vectors)\n",
    "    \n",
    "    v_index = np.argsort( values )\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    print(now)\n",
    "    print('第二固有値、固有ベクトル取得')\n",
    "    \n",
    "    eigen = values[ v_index[1] ]\n",
    "    eigen_vector = vectors[:, v_index[1] ]\n",
    "    \n",
    "    print(eigen)\n",
    "    \n",
    "    \"\"\"\n",
    "    eigen = values[ 1 ]\n",
    "    eigen_vector = vectors[:,1]\n",
    "    \"\"\"\n",
    "    \n",
    "    return eigen, eigen_vector, values, vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649e8d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabor(img,k,sigma,lam,gam):\n",
    "    gabor = cv2.getGaborKernel((k,k), sigma, np.radians(0), lam, gam, 0)\n",
    "    img_0 = cv2.filter2D(img, cv2.CV_32S, gabor,cv2.BORDER_CONSTANT)\n",
    "\n",
    "    gabor = cv2.getGaborKernel((k,k), sigma, np.radians(10), lam, gam, 0)\n",
    "    img_10 = cv2.filter2D(img, cv2.CV_32S, gabor,cv2.BORDER_CONSTANT)\n",
    "\n",
    "    gabor = cv2.getGaborKernel((k,k), sigma, np.radians(20), lam, gam, 0)\n",
    "    img_20 = cv2.filter2D(img, cv2.CV_32S, gabor,cv2.BORDER_CONSTANT)\n",
    "\n",
    "    gabor = cv2.getGaborKernel((k,k), sigma, np.radians(30), lam, gam, 0)\n",
    "    img_30 = cv2.filter2D(img, cv2.CV_32S, gabor,cv2.BORDER_CONSTANT)\n",
    "\n",
    "    gabor = cv2.getGaborKernel((k,k), sigma, np.radians(40), lam, gam, 0)\n",
    "    img_40 = cv2.filter2D(img, cv2.CV_32S, gabor,cv2.BORDER_CONSTANT)\n",
    "\n",
    "    gabor = cv2.getGaborKernel((k,k), sigma, np.radians(50), lam, gam, 0)\n",
    "    img_50 = cv2.filter2D(img, cv2.CV_32S, gabor,cv2.BORDER_CONSTANT)\n",
    "\n",
    "    gabor = cv2.getGaborKernel((k,k), sigma, np.radians(60), lam, gam, 0)\n",
    "    img_60 = cv2.filter2D(img, cv2.CV_32S, gabor,cv2.BORDER_CONSTANT)\n",
    "\n",
    "    gabor = cv2.getGaborKernel((k,k), sigma, np.radians(70), lam, gam, 0)\n",
    "    img_70 = cv2.filter2D(img, cv2.CV_32S, gabor,cv2.BORDER_CONSTANT)\n",
    "    \n",
    "    gabor = cv2.getGaborKernel((k,k), sigma, np.radians(80), lam, gam, 0)\n",
    "    img_80 = cv2.filter2D(img, cv2.CV_32S, gabor,cv2.BORDER_CONSTANT)\n",
    "\n",
    "    gabor = cv2.getGaborKernel((k,k), sigma, np.radians(90), lam, gam, 0)\n",
    "    img_90 = cv2.filter2D(img, cv2.CV_32S, gabor,cv2.BORDER_CONSTANT)\n",
    "\n",
    "    gabor = cv2.getGaborKernel((k,k), sigma, np.radians(100), lam, gam, 0)\n",
    "    img_100 = cv2.filter2D(img, cv2.CV_32S, gabor,cv2.BORDER_CONSTANT)\n",
    "\n",
    "    gabor = cv2.getGaborKernel((k,k), sigma, np.radians(110), lam, gam, 0)\n",
    "    img_110 = cv2.filter2D(img, cv2.CV_32S, gabor,cv2.BORDER_CONSTANT)\n",
    "\n",
    "    gabor = cv2.getGaborKernel((k,k), sigma, np.radians(120), lam, gam, 0)\n",
    "    img_120 = cv2.filter2D(img, cv2.CV_32S, gabor,cv2.BORDER_CONSTANT)\n",
    "    \n",
    "    gabor = cv2.getGaborKernel((k,k), sigma, np.radians(130), lam, gam, 0)\n",
    "    img_130 = cv2.filter2D(img, cv2.CV_32S, gabor,cv2.BORDER_CONSTANT)\n",
    "\n",
    "    gabor = cv2.getGaborKernel((k,k), sigma, np.radians(140), lam, gam, 0)\n",
    "    img_140 = cv2.filter2D(img, cv2.CV_32S, gabor,cv2.BORDER_CONSTANT)\n",
    "\n",
    "    gabor = cv2.getGaborKernel((k,k), sigma, np.radians(150), lam, gam, 0)\n",
    "    img_150 = cv2.filter2D(img, cv2.CV_32S, gabor,cv2.BORDER_CONSTANT)\n",
    "\n",
    "    gabor = cv2.getGaborKernel((k,k), sigma, np.radians(160), lam, gam, 0)\n",
    "    img_160 = cv2.filter2D(img, cv2.CV_32S, gabor,cv2.BORDER_CONSTANT)\n",
    "\n",
    "    gabor = cv2.getGaborKernel((k,k), sigma, np.radians(170), lam, gam, 0)\n",
    "    img_170 = cv2.filter2D(img, cv2.CV_32S, gabor,cv2.BORDER_CONSTANT)\n",
    "    \n",
    "    return img_0,img_10,img_20,img_30,img_40,img_50,img_60,img_70,img_80,img_90,img_100,img_110,img_120,img_130,img_140,img_150,img_160,img_170"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c135b2b8",
   "metadata": {},
   "source": [
    "### 隣接行列作成（距離、特徴重みあり）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4a3d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#入力CT画像の番号\n",
    "img_num = 680\n",
    "\n",
    "#ノード数カウント用\n",
    "cnt = 1\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "print(now)\n",
    "print('ノード番号付与中')\n",
    "\n",
    "#入力画像を取得\n",
    "img = cv2.imread('../../flower_CT_photo/ORA/[vg-data] ORA/volume_1/ORA-{0:03d}.tif'.format(img_num),0)\n",
    "#画像のサイズを取得\n",
    "height,width = img.shape\n",
    "\n",
    "#入力画像にノンローカルミーンフィルタを適用し2値化\n",
    "img_NLMD = cv2.fastNlMeansDenoising(img,h=6)\n",
    "th_img = np.where(img>50 ,255,0)\n",
    "\n",
    "#ノード番号を格納する配列を定義\n",
    "temp = np.zeros((height,width),dtype = 'i4')\n",
    "\n",
    "#閾値以上のピクセルにノード番号付与\n",
    "for y in tqdm(range(height)):\n",
    "    for x in range(width):\n",
    "        if(th_img[y,x]==255):\n",
    "            temp[y,x] = cnt\n",
    "            cnt += 1\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "print(now)\n",
    "print('隣接行列を宣言')\n",
    "\n",
    "#スパース行列を使うときは以下\n",
    "A = lil_matrix((cnt-1,cnt-1),dtype='float')\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "print(now)\n",
    "print('ガボールフィルタ')\n",
    "\n",
    "#パラメータ設定\n",
    "k = 30\n",
    "sigma = 1.11\n",
    "lam = 10\n",
    "gam = 0.09\n",
    "img_0,img_10,img_20,img_30,img_40,img_50,img_60,img_70,img_80,img_90,img_100,\\\n",
    "img_110,img_120,img_130,img_140,img_150,img_160,img_170 = gabor(img_NLMD,k,sigma,lam,gam)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "print(now)\n",
    "print('隣接行列作成中')\n",
    "\n",
    "r_th = 20\n",
    "a = 0.001\n",
    "b = 0.001\n",
    "\n",
    "for y in tqdm(range(height)):\n",
    "    for x in range(width):\n",
    "\n",
    "        if(temp[y,x]>0):\n",
    "            node1 = temp[y,x]-1\n",
    "            for y_t in range(y,y+25):\n",
    "                if(y == y_t):\n",
    "                    for x_t in range(x,x+25):\n",
    "                        if((temp[y_t,x_t]>0) and (y != y_t) and (x != x_t)):\n",
    "                            node2 = temp[y_t,x_t]-1\n",
    "                            r = math.sqrt((x-x_t)**2 + (y-y_t)**2)\n",
    "                            if(r < r_th):\n",
    "\n",
    "                                esc = 0\n",
    "                                flag = 0\n",
    "                                i = 0\n",
    "\n",
    "                                rr,cc = line(y,x,y_t,x_t)\n",
    "\n",
    "                                while(esc==0):\n",
    "                                    if(th_img[rr[i],cc[i]]==0):\n",
    "                                        flag = 1\n",
    "                                        esc = 1\n",
    "                                    elif(i < rr.shape[0]-1):\n",
    "                                        i += 1\n",
    "                                    else:\n",
    "                                        esc = 1\n",
    "\n",
    "                                if(flag==0):\n",
    "\n",
    "                                    d = math.sqrt((img_0[y,x]-img_0[y_t,x_t])**2+(img_10[y,x]-img_10[y_t,x_t])**2+(img_20[y,x]-img_20[y_t,x_t])**2+\\\n",
    "                                                  (img_30[y,x]-img_30[y_t,x_t])**2+(img_40[y,x]-img_40[y_t,x_t])**2+(img_50[y,x]-img_50[y_t,x_t])**2+\\\n",
    "                                                  (img_60[y,x]-img_60[y_t,x_t])**2+(img_70[y,x]-img_70[y_t,x_t])**2+(img_80[y,x]-img_80[y_t,x_t])**2+\\\n",
    "                                                  (img_90[y,x]-img_90[y_t,x_t])**2+(img_100[y,x]-img_100[y_t,x_t])**2+(img_110[y,x]-img_110[y_t,x_t])**2+\\\n",
    "                                                  (img_120[y,x]-img_120[y_t,x_t])**2+(img_130[y,x]-img_130[y_t,x_t])**2+(img_140[y,x]-img_140[y_t,x_t])**2+\\\n",
    "                                                  (img_150[y,x]-img_150[y_t,x_t])**2+(img_160[y,x]-img_160[y_t,x_t])**2)+(img_170[y,x]-img_170[y_t,x_t])**2\n",
    "\n",
    "                                    W = math.exp(-a*r)+math.exp(-b*d)\n",
    "\n",
    "                                    A[node1,node2] = W\n",
    "                                    A[node2,node1] = W\n",
    "                else:\n",
    "                    for x_t in range(x-25,x+25):\n",
    "                        if((temp[y_t,x_t]>0) and (y != y_t) and (x != x_t)):\n",
    "                            node2 = temp[y_t,x_t]-1\n",
    "                            r = math.sqrt((x-x_t)**2 + (y-y_t)**2)\n",
    "                            if(r < r_th):\n",
    "\n",
    "                                esc = 0\n",
    "                                flag = 0\n",
    "                                i = 0\n",
    "\n",
    "                                rr,cc = line(y,x,y_t,x_t)\n",
    "\n",
    "                                while(esc==0):\n",
    "                                    if(th_img[rr[i],cc[i]]==0):\n",
    "                                        flag = 1\n",
    "                                        esc = 1\n",
    "                                    elif(i < rr.shape[0]-1):\n",
    "                                        i += 1\n",
    "                                    else:\n",
    "                                        esc = 1\n",
    "\n",
    "                                if(flag==0):\n",
    "                                    d = math.sqrt((img_0[y,x]-img_0[y_t,x_t])**2+(img_10[y,x]-img_10[y_t,x_t])**2+(img_20[y,x]-img_20[y_t,x_t])**2+\\\n",
    "                                                  (img_30[y,x]-img_30[y_t,x_t])**2+(img_40[y,x]-img_40[y_t,x_t])**2+(img_50[y,x]-img_50[y_t,x_t])**2+\\\n",
    "                                                  (img_60[y,x]-img_60[y_t,x_t])**2+(img_70[y,x]-img_70[y_t,x_t])**2+(img_80[y,x]-img_80[y_t,x_t])**2+\\\n",
    "                                                  (img_90[y,x]-img_90[y_t,x_t])**2+(img_100[y,x]-img_100[y_t,x_t])**2+(img_110[y,x]-img_110[y_t,x_t])**2+\\\n",
    "                                                  (img_120[y,x]-img_120[y_t,x_t])**2+(img_130[y,x]-img_130[y_t,x_t])**2+(img_140[y,x]-img_140[y_t,x_t])**2+\\\n",
    "                                                  (img_150[y,x]-img_150[y_t,x_t])**2+(img_160[y,x]-img_160[y_t,x_t])**2)+(img_170[y,x]-img_170[y_t,x_t])**2\n",
    "\n",
    "                                    W = math.exp(-a*r)+math.exp(-b*d)\n",
    "                                    \n",
    "                                    A[node1,node2] = W\n",
    "                                    A[node2,node1] = W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0540376",
   "metadata": {},
   "source": [
    "### 固有値計算の表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f21bcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A = csr_matrix(A)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "print(now)\n",
    "print('固有値、固有ベクトル計算中')\n",
    "\n",
    "eig, vector ,values ,vectors= eigen_2nd(A,cnt)\n",
    "\n",
    "T = np.zeros((vectors.shape[0],vectors.shape[1]))\n",
    "\n",
    "vectors = vectors.astype('f8')\n",
    "\n",
    "for n in tqdm(range(vectors.shape[0])):\n",
    "    sum_u = 0\n",
    "    for k in range(vectors.shape[1]):\n",
    "        sum_u += vectors[n,k] ** (2)\n",
    "    \n",
    "    sum_u = math.sqrt(sum_u)\n",
    "    \n",
    "    for k in range(vectors.shape[1]):\n",
    "        T[n,k] = vectors[n,k]/sum_u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f454824b",
   "metadata": {},
   "source": [
    "### 色付け"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51af3027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "cluster_num = 250\n",
    "\n",
    "color_code = np.zeros((cluster_num,3))\n",
    "\n",
    "for i in range(cluster_num):\n",
    "    color_code[i] = (np.random.choice(range(256), size=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62161f93",
   "metadata": {},
   "source": [
    "### k-meansでクラスタ分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0529eadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = KMeans(n_clusters=200).fit_predict(T)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331fd517",
   "metadata": {},
   "source": [
    "#### k-meansのクラスタに色付け"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a1276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_col = cv2.imread('../../flower_CT_photo/ORA/[vg-data] ORA/volume_1/ORA-{0:03d}.tif'.format(img_num))\n",
    "\n",
    "for y in range(img_col.shape[0]):\n",
    "    for x in range(img_col.shape[1]):\n",
    "        if(temp[y,x]>0):\n",
    "            i = temp[y,x]-1\n",
    "            img_col[y,x] = color_code[pred[i]]\n",
    "            \n",
    "cv2.imwrite('Output/Spectral_Clustering_ORA-{0:03d}/ORA-{0:03d}_NLMD-h6-50_norm2_k30gabor-18-NLMD_r-20d_color_k-means-200_T_fixed.png'.format(img_num),img_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6998ff0d",
   "metadata": {},
   "source": [
    "### 細線化による分岐点検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6250a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def junk(img_skel,img):\n",
    "    height,width = img_skel.shape\n",
    "    temp_j = np.zeros((height,width))\n",
    "    \n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            if(img_skel[y,x]==255):\n",
    "                check = 0\n",
    "                cnt = 1\n",
    "                temp_l = np.zeros((3,3))\n",
    "                \n",
    "                if(img_skel[y-1,x-1]==255):\n",
    "                    cnt += 1\n",
    "                    temp_l[0,0] = 1\n",
    "                if(img_skel[y-1,x]==255):\n",
    "                    cnt += 1\n",
    "                    temp_l[0,1] = 1\n",
    "                if(img_skel[y-1,x+1]==255):\n",
    "                    cnt += 1\n",
    "                    temp_l[0,2] = 1\n",
    "                if(img_skel[y,x-1]==255):\n",
    "                    cnt += 1\n",
    "                    temp_l[1,0] = 1\n",
    "                if(img_skel[y,x+1]==255):\n",
    "                    cnt += 1\n",
    "                    temp_l[1,2] = 1\n",
    "                if(img_skel[y+1,x-1]==255):\n",
    "                    cnt += 1\n",
    "                    temp_l[2,0] = 1\n",
    "                if(img_skel[y+1,x]==255):\n",
    "                    cnt += 1\n",
    "                    temp_l[2,1] = 1\n",
    "                if(img_skel[y+1,x+1]==255):\n",
    "                    cnt += 1\n",
    "                    temp_l[2,2] = 1\n",
    "                \n",
    "                for y_l in range(3):\n",
    "                    for x_l in range(3):\n",
    "                        if(temp_l[y_l,x_l] == 1):\n",
    "                            if((y_l-1)>=0):\n",
    "                                if(temp_l[y_l-1,x_l] == 1):\n",
    "                                    check = 1\n",
    "                            if((y_l+1)<3):\n",
    "                                if(temp_l[y_l+1,x_l] == 1):\n",
    "                                    check = 1\n",
    "                            if((x_l-1)>=0):\n",
    "                                if(temp_l[y_l,x_l-1] == 1):\n",
    "                                    check = 1\n",
    "                            if((x_l+1)<3):\n",
    "                                if(temp_l[y_l,x_l+1] == 1):\n",
    "                                    check = 1\n",
    "\n",
    "                if(cnt == 2):\n",
    "                    temp_j[y,x] = 2\n",
    "                elif((cnt > 3) and (check == 0)):\n",
    "                    temp_j[y,x] = 1\n",
    "                elif(cnt>5):\n",
    "                    temp_j[y,x] = 1\n",
    "                    \n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            if(temp_j[y,x]==1):\n",
    "                cv2.rectangle(img, (x-3, y-3), (x+3, y+3), (0, 0, 255))\n",
    "                cv2.rectangle(img_skel, (x-3, y-3), (x+3, y+3), 0, thickness=-1)\n",
    "            elif(temp_j[y,x]==2):\n",
    "                cv2.rectangle(img, (x-3, y-3), (x+3, y+3), (0, 255, 0))\n",
    "                    \n",
    "    return temp_j,img,img_skel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5607233",
   "metadata": {},
   "source": [
    "### 細線化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055696f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skel(img_num):\n",
    "\n",
    "    #Original\n",
    "    img_col = cv2.imread('../../flower_CT_photo/ORA/[vg-data] ORA/volume_1/ORA-{0:03d}.tif'.format(img_num))\n",
    "\n",
    "    #NLMDを用いた2値化\n",
    "    img = cv2.imread('../../flower_CT_photo/ORA/[vg-data] ORA/volume_1/ORA-{0:03d}.tif'.format(img_num),0)\n",
    "    img = cv2.fastNlMeansDenoising(img,h=6)\n",
    "    th_img = np.where(img>50 ,1 ,0)\n",
    "\n",
    "    # 細線化(スケルトン化) Zha84\n",
    "    skeleton = skeletonize(th_img)\n",
    "\n",
    "    skel_b = np.zeros((img.shape[0],img.shape[1]))\n",
    "    skel_b[skeleton==True] = 255\n",
    "\n",
    "    #細線化画像による分岐点探索\n",
    "    temp_j,img_j,img_skel = junk(skel_b,img_col)\n",
    "    \n",
    "    cv2.imwrite('Output/Spectral_Clustering_ORA-{0:03d}/ORA-{0:03d}_h6-50_skel.png'.format(img_num),img_j)\n",
    "    \n",
    "    return temp_j,img_skel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa86fd4",
   "metadata": {},
   "source": [
    "### 分岐点探索後、周辺の同じクラスタ番号を消去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd595f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "j_p,img_skel= skel(img_num)\n",
    "\n",
    "cluster = np.zeros((height,width))\n",
    "del_cluster = np.zeros((height,width))\n",
    "\n",
    "for y in tqdm(range(height)):\n",
    "    for x in range(width):\n",
    "        if(temp[y,x]>0):\n",
    "            i = temp[y,x]-1\n",
    "            cluster[y,x] = pred[i]            \n",
    "\n",
    "img_g = cv2.imread('../../flower_CT_photo/ORA/[vg-data] ORA/volume_1/ORA-{0:03d}.tif'.format(img_num),0)\n",
    "            \n",
    "for y in tqdm(range(height)):\n",
    "    for x in range(width):\n",
    "        if(j_p[y,x]==1):\n",
    "            if(cluster[y,x]!=0):\n",
    "                p_pred = cluster[y,x]\n",
    "                cluster[y,x] = 0\n",
    "                del_cluster[y,x] = img_NLMD[y,x]\n",
    "                for y_t in range(height):\n",
    "                    for x_t in range(width):\n",
    "                        if(p_pred == cluster[y_t,x_t]):\n",
    "                            cluster[y_t,x_t] = 0\n",
    "                            del_cluster[y,x] = img_NLMD[y,x]\n",
    "                    \n",
    "img_col = cv2.imread('../../flower_CT_photo/ORA/[vg-data] ORA/volume_1/ORA-{0:03d}.tif'.format(img_num))\n",
    "\n",
    "for y in range(img_col.shape[0]):\n",
    "    for x in range(img_col.shape[1]):\n",
    "        if(temp[y,x]>0):\n",
    "            if(cluster[y,x] != 0):\n",
    "                i = temp[y,x]-1\n",
    "                img_col[y,x] = color_code[pred[i]]\n",
    "\n",
    "cv2.imwrite('Output/Spectral_Clustering_ORA-{0:03d}/ORA-{0:03d}_h6-50_norm2_k30gabor-18-nonpro_r-20d_color_k-means-200_T_fixed_junk_0.png'.format(img_num),img_col)\n",
    "\n",
    "cv2.imwrite('Output/Spectral_Clustering_ORA-{0:03d}/ORA-{0:03d}_h6-50_norm2_k30gabor-18-nonpro_r-20d_color_k-means-200_T_fixed_junk-only.png'.format(img_num),del_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ac1233",
   "metadata": {},
   "source": [
    "### 分岐点を除去した細線化画像にラベリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ac55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_col_skel = cv2.imread('../../flower_CT_photo/ORA/[vg-data] ORA/volume_1/ORA-{0:03d}.tif'.format(img_num))\n",
    "\n",
    "img_skel = img_skel.astype('u1')\n",
    "\n",
    "nLabels, labelImages_skel, data, center = cv2.connectedComponentsWithStatsWithAlgorithm(img_skel, 8, cv2.CV_16U, cv2.CCL_DEFAULT)\n",
    "\n",
    "colors = []\n",
    "\n",
    "for i in range(1, n + 1):\n",
    "    colors.append(np.array([random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]))\n",
    "    \n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        if(labelImages_skel[y,x]>0):\n",
    "            img_col_skel[y,x]=colors[int(labelImages_skel[y,x])]\n",
    "            \n",
    "cv2.imwrite('Output/Spectral_Clustering_ORA-{0:03d}/ORA-{0:03d}_skel_label.png'.format(img_num),img_col_skel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac78f45",
   "metadata": {},
   "source": [
    "### ラベリング・ノイズ除去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d416eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_img_clu = cv2.imread('../../flower_CT_photo/ORA/[vg-data] ORA/volume_1/ORA-{0:03d}.tif'.format(img_num),0)\n",
    "\n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        if(cluster[y,x]>0):\n",
    "            th_img_clu[y,x]=255\n",
    "        else:\n",
    "            th_img_clu[y,x]=0\n",
    "\n",
    "cv2.imwrite('Output/Spectral_Clustering_ORA-{0:03d}/ORA-{0:03d}_h6-50_norm2_k30gabor-18-nonpro_r-20d_color_k-means-200_T_fixed_junk-0_th.png'.format(img_num),th_img_clu)\n",
    "\n",
    "img_col = cv2.imread('../../flower_CT_photo/ORA/[vg-data] ORA/volume_1/ORA-{0:03d}.tif'.format(img_num))\n",
    "\n",
    "# ラベリング処理\n",
    "nLabels, labelImages, data, center = cv2.connectedComponentsWithStatsWithAlgorithm(th_img_clu, 8, cv2.CV_16U, cv2.CCL_DEFAULT)\n",
    "\n",
    "# オブジェクト情報を項目別に抽出\n",
    "n = nLabels - 1\n",
    "\n",
    "label_fix = np.zeros(nLabels)\n",
    "\n",
    "# オブジェクト情報を利用して15ピクセル以下のラベルを削除\n",
    "for i in range(1,nLabels):\n",
    "\n",
    "    size = data[i,4]\n",
    "    if(size<15):\n",
    "        label_fix[i]=0\n",
    "    else:\n",
    "        label_fix[i]=i\n",
    "\n",
    "#色情報の定義\n",
    "colors = []    \n",
    "\n",
    "for i in range(1, nLabels+1):\n",
    "    colors.append(np.array([random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]))\n",
    "    \n",
    "#2値化用の配列\n",
    "label_th = np.zeros((height,width))\n",
    "    \n",
    "#ラベリングの色を付与・2値化\n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        if((labelImages[y,x]>0)and(label_fix[labelImages[y,x]]>0)):\n",
    "            img_col[y,x]=colors[int(label_fix[int(labelImages[y,x])])]\n",
    "            label_th[y,x]=255\n",
    "        else:\n",
    "            cluster[y,x]=0\n",
    "\n",
    "#ラベリング結果を保存\n",
    "cv2.imwrite('Output/Spectral_Clustering_ORA-{0:03d}/ORA-{0:03d}_h6-50_norm2_k30gabor-18-nonpro_r-20d_color_k-means-200_T_fixed_junk-0_label.png'.format(img_num),img_col)\n",
    "#ノイズ除去した画像を保存\n",
    "cv2.imwrite('Output/Spectral_Clustering_ORA-{0:03d}/ORA-{0:03d}_h6-50_norm2_k30gabor-18-nonpro_r-20d_color_k-means-200_T_fixed_junk-0_label_th.png'.format(img_num),label_th)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2630bcc3",
   "metadata": {},
   "source": [
    "### 細線化結果を用いてクラスタの統合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a6bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#クラスタ統合用\n",
    "c_num = np.zeros((201))\n",
    "\n",
    "#細線上を辿り、1つの細線に属しているクラスタを1つのクラスタに統合\n",
    "for y in tqdm(range(height)):\n",
    "    for x in range(width):\n",
    "        if((img_skel[y,x]>0)and(cluster[y,x]>0)):\n",
    "            c_num[int(cluster[y,x])] = labelImages_skel[y,x]\n",
    "\n",
    "#統合後のクラスタを格納\n",
    "cluster_fix = np.zeros((height,width))\n",
    "\n",
    "for y in tqdm(range(height)):\n",
    "    for x in range(width):\n",
    "        if(cluster[y,x]>0):\n",
    "            cluster_fix[y,x]= c_num[int(cluster[y,x])]\n",
    "\n",
    "#統合後のクラスタを保存\n",
    "img_col = cv2.imread('../../flower_CT_photo/ORA/[vg-data] ORA/volume_1/ORA-{0:03d}.tif'.format(img_num))\n",
    "            \n",
    "for i in range(1, 201):\n",
    "    colors.append(np.array([random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]))\n",
    "    \n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        if(cluster_fix[y,x]>0):\n",
    "            img_col[y,x]=colors[int(cluster_fix[y,x])]\n",
    "\n",
    "cv2.imwrite('Output/Spectral_Clustering_ORA-{0:03d}/ORA-{0:03d}_h6-50_norm2_k30gabor-18-nonpro_r-20d_color_k-means-200_T_fixed_junk-0_label_skel.png'.format(img_num),img_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b2e2cb",
   "metadata": {},
   "source": [
    "### 統合後に同じクラスタが離れている場合は分離"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80479a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_cl = 200\n",
    "chk_cl = np.zeros(300)\n",
    "\n",
    "for y in tqdm(range(height)):\n",
    "    for x in range(width):\n",
    "        if((cluster_fix[y,x]>0)and(chk_cl[int(cluster_fix[y,x])]==0)):\n",
    "            \n",
    "            temp_cl = np.zeros((height,width))\n",
    "            \n",
    "            for y_t in range(height):\n",
    "                for x_t in range(width):\n",
    "                    if(cluster_fix[y,x]==cluster_fix[y_t,x_t]):\n",
    "                        temp_cl[y_t,x_t] = 255\n",
    "\n",
    "            temp_cl = temp_cl.astype('u1')\n",
    "            \n",
    "            nLabels_temp, labelImages_temp, data_temp, center_temp = cv2.connectedComponentsWithStatsWithAlgorithm(temp_cl, 8, cv2.CV_16U, cv2.CCL_DEFAULT)\n",
    "            \n",
    "            chk_cl[int(cluster_fix[y,x])]=1\n",
    "            if(nLabels_temp>2):\n",
    "                for y_t in range(height):\n",
    "                    for x_t in range(width):\n",
    "                        if(labelImages_temp[y_t,x_t]>0):\n",
    "                            cluster_fix[y_t,x_t] = cnt_cl+labelImages_temp[y_t,x_t]\n",
    "                cnt_cl += nLabels_temp-1\n",
    "                    \n",
    "c_num_fix = np.zeros((300))\n",
    "\n",
    "for y in tqdm(range(height)):\n",
    "    for x in range(width):\n",
    "        if((img_skel[y,x]>0)and(cluster_fix[y,x]>0)):\n",
    "            c_num_fix[int(cluster_fix[y,x])] = labelImages_skel[y,x]\n",
    "\n",
    "cluster_fix2 = np.zeros((height,width))\n",
    "            \n",
    "for y in tqdm(range(height)):\n",
    "    for x in range(width):\n",
    "        if(cluster[y,x]>0):\n",
    "            cluster_fix2[y,x]= c_num_fix[int(cluster_fix[y,x])]\n",
    "\n",
    "img_col = cv2.imread('../../flower_CT_photo/ORA/[vg-data] ORA/volume_1/ORA-{0:03d}.tif'.format(img_num))\n",
    "            \n",
    "colors = []\n",
    "for i in range(1, cnt_cl+1):\n",
    "    colors.append(np.array([random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]))\n",
    "    \n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        if(cluster_fix2[y,x]>0):\n",
    "            img_col[y,x]=colors[int(cluster_fix2[y,x])]\n",
    "\n",
    "cv2.imwrite('Output/Spectral_Clustering_ORA-{0:03d}/ORA-{0:03d}_h6-50_norm2_k30gabor-18-nonpro_r-20d_color_k-means-200_T_fixed_junk-0_label_skel_fix.png'.format(img_num),img_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aef86d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
